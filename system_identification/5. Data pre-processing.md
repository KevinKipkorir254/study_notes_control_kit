# DATA PRE-PROCESSING

When the data have been collected from the identification experiment, they are not
likely to be in shape for immediate use in identification algorithms. There are several
possible deficiencies in the data that should be attended to:
1. High-frequency disturbances in the data record, above the frequencies of interest
   to the system dynamics
2. Occasional bursts and outliers, missing data, non-continuous data records
3. Drift and offset, low-frequency disturbances, possibly of periodic character

It must be stressed that in off-line applications, one should always first plot the data
in order to inspect them for these deficiencies. In this section we shall discuss how
to preprocess the data so as to avoid problems in the identification procedures later.

## DRIFTS AND DETRENDING

Low-frequency disturbances, offsets, trends, drift, and periodic (seasonal) variations
are not uncommon in data. They typically stem from external sources that we may
or may not prefer to include in the modeling. There are basically two different
approaches to dealing with such problems:
 1. Removing the disturbances by explicit pretreatment of the data
 2. Letting the noise model take care of the disturbances

The first approach involves removing trends and offsets by direct subtraction,
while the second relies on noise models with poles on or close to the unit circle,
like the ARIMA models much used in the Box and Jenkins approach.

### Signal offsets

We shall illustrate the two approaches applied to the offset problem. The standard
linear models that we use. like,

$$A(q)y(t) = B(q)u(t) + v(t)$$  (1)

describe the relationship between it u and y. There are at least six ways to deal with
this problem:

1. Let $$y(t)$$ and $$u(t)$$ be deviations from a physical equilibrium: 
The most natural approach is to determine the level $$\bar{y}$$ that corresponds to a constant $$u_m(t) = \bar{u}$$ close to the desired operating point. Then define

$$y(t) = y_m(t) - \bar{y}$$ (3a)

$$u(t) = u_m(t) - \bar{u}$$ (3b)

as the deviations from this equilibrium. These translated variables will automatically satisfy (14.2), making both members equal to zero, and (2) will thus not influence the fit in (1). This approach emphasizes the physical interpretation of (1) as a linearization around the equilibrium.

2. Subracting sample means: A sound approach is to define

$$\bar{u} = \frac{1}{N} \sum_{t=1}^N u_m(t)$$ (4a)

$$\bar{y} = \frac{1}{N} \sum_{t=1}^N y_m(t)$$ (4b)

and then use (14.3). If an input $$u_m(t)$$ that varies around $$\bar{u}$$ leads to an output that varies around $$\bar{y}$$, then $$(\bar{u}, \bar{y})$$ is likely to be close to an equilibrium point of the system. Approach 2 is thus closely related to the first approach.

3. Estimating the offset: One could also model the system using variables in the original physical units and add a constant that takes care of the offsets:

$$A(q)y_m(t) = B(q)u_m(t) + a + v(t)$$ (5) 

Comparing with (1) to (3), we see that $$a$$ corresponds to $$A(1)\bar{y} - B(1)\bar{u}$$. The value $$a$$ is then included in the parameter vector $$\theta$$ and estimated from data. It turns out that this approach in fact is a slight variant of the second approach.

4. Using a noise model with integration (≡ differencing the data): In (5) the constant $$a$$ could be viewed as a constant disturbance, which is modeled as

$$a\delta(t) = \frac{a}{1 - q^{-1}}$$ (6)

where $$\delta(t)$$ is the unit pulse at time zero. The model then reads

$$y_m(t) = \frac{B(q)}{A(q)}u_m(t) + \frac{1}{(1 - q^{-1})A(q)}w(t)$$ (7)

where $$w(t)$$ is the combined noise source $$a\delta(t) + v(t) - v(t - 1)$$. The offset $$a$$ can thus be described by changing the noise model from $$1/A(q)$$ to $$1/[(1 - q^{-1})A(q)]$$. According to what we noted in (7.14), this is equivalent to prefiltering the data through the filter $$L(q) = 1 - q^{-1}$$, that is, differencing the data:

$$y_f(t) = L(q)y_m(t) = y_m(t) - y_m(t - 1)$$ (8a)

$$u_f(t) = L(q)u_m(t) = u_m(t) - u_m(t - 1)$$ (8b)

5. Extending the noise model: Notice that the model (7) becomes a special case of (1) if the orders of the       $$A$$ and $$B$$ polynomials in (1) are increased by 1. Then a common factor $$1 - q^{-1}$$ can be included in  $$A (q)$$ and $$B(q)$$. This means that a higher-order model, when applied to the raw data $$y_m$$, will converge to a model like (7).

6. High pass filter: Differencing data is a rather drastic filter for removing
   a static component. Any high-pass filter that has gain (close to) zero at frequency
   zero will have the same effect

## OUTLIERS AND MISSING DATA

In practice, the data acquisition equipment is not perfect. It may be that single values
or portions of the input-output data are missing, due to malfunctions in the sensors
or communication links. It may also be that certain measured values are in obvious
error due to measurement failures. Such bad values are often called outliers, and
may have a substantial negative effect on the estimate. Bad values are often much
easier to detect in a residual plot
To deal with outliers and missing data, there are a few possibilities. One is to
cut out segments of the data sequence so that portions with bad data are avoided.
The segments can then be merged using the techniques of Section 14.3. For a data
set with many inputs and outputs it might be difficult—in certain applications—to
find data segments that are "clean" in all variables. It is then better to treat outliers,
both in inputs and outputs, as missing data and view them as unknown parameters.

### Dealing with missing data

Assume, for the moment, that we have a model $$M(\theta)$$ that describes the relationship between the input-output data. In the basic linear predictor form (4.6) it is given by

$$\hat{y}(t|\theta) = \sum_{k=1}^{p} g(t - k, \theta) u(k) + \sum_{k=1}^{m} h(t - k, \theta) y(k)$$ (14.11)

Suppose now that some of the input-output data are missing. One must distinguish between missing inputs and missing outputs, since they should be handled differently. Let us first consider missing inputs.





